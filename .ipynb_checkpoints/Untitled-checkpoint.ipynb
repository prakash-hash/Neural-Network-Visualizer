{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and splitting the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26903ac47f0>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[1],cmap='binary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting all the unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot Encoding the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_encoded shape: (60000, 10)\n",
      "y_test_encoded shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train_encoded shape:\",y_train_encoded.shape)\n",
    "print(\"y_test_encoded shape:\",y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking one of the encoded target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_encoded[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatning the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_reshaped shape: (60000, 784)\n",
      "x_test_reshaped shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_reshped = np.reshape(x_train, (60000, 784))\n",
    "x_test_reshped = np.reshape(x_test, (10000, 784))\n",
    "\n",
    "print(\"x_train_reshaped shape:\",x_train_reshped.shape)\n",
    "print(\"x_test_reshaped shape:\",x_test_reshped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of flatanned image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 6, 7, 10, 12, 19, 21, 25, 28, 29, 37, 38, 47, 48, 50, 51, 54, 56, 57, 60, 63, 71, 75, 76, 79, 84, 85, 86, 96, 112, 114, 121, 122, 128, 130, 131, 135, 141, 145, 146, 148, 159, 162, 163, 165, 167, 168, 173, 178, 179, 186, 189, 190, 195, 196, 198, 199, 202, 208, 215, 223, 224, 225, 227, 228, 229, 230, 233, 237, 238, 239, 240, 243, 246, 249, 252, 253, 255}\n"
     ]
    }
   ],
   "source": [
    "print(set(x_train_reshped[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_normalised = (x_train_reshped)/255\n",
    "x_test_normalised = (x_test_reshped)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation='sigmoid', input_shape=(784,)),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting/Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 - 1s - loss: 0.3306 - accuracy: 0.9176\n",
      "Epoch 2/20\n",
      "30/30 - 1s - loss: 0.3183 - accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "30/30 - 1s - loss: 0.3074 - accuracy: 0.9219\n",
      "Epoch 4/20\n",
      "30/30 - 1s - loss: 0.2973 - accuracy: 0.9238\n",
      "Epoch 5/20\n",
      "30/30 - 1s - loss: 0.2882 - accuracy: 0.9257\n",
      "Epoch 6/20\n",
      "30/30 - 1s - loss: 0.2799 - accuracy: 0.9273\n",
      "Epoch 7/20\n",
      "30/30 - 1s - loss: 0.2724 - accuracy: 0.9281\n",
      "Epoch 8/20\n",
      "30/30 - 1s - loss: 0.2649 - accuracy: 0.9299\n",
      "Epoch 9/20\n",
      "30/30 - 1s - loss: 0.2582 - accuracy: 0.9312\n",
      "Epoch 10/20\n",
      "30/30 - 1s - loss: 0.2520 - accuracy: 0.9330\n",
      "Epoch 11/20\n",
      "30/30 - 1s - loss: 0.2459 - accuracy: 0.9342\n",
      "Epoch 12/20\n",
      "30/30 - 1s - loss: 0.2404 - accuracy: 0.9351\n",
      "Epoch 13/20\n",
      "30/30 - 1s - loss: 0.2349 - accuracy: 0.9369\n",
      "Epoch 14/20\n",
      "30/30 - 1s - loss: 0.2298 - accuracy: 0.9380\n",
      "Epoch 15/20\n",
      "30/30 - 1s - loss: 0.2250 - accuracy: 0.9391\n",
      "Epoch 16/20\n",
      "30/30 - 1s - loss: 0.2202 - accuracy: 0.9403\n",
      "Epoch 17/20\n",
      "30/30 - 1s - loss: 0.2160 - accuracy: 0.9413\n",
      "Epoch 18/20\n",
      "30/30 - 1s - loss: 0.2117 - accuracy: 0.9426\n",
      "Epoch 19/20\n",
      "30/30 - 1s - loss: 0.2075 - accuracy: 0.9433\n",
      "Epoch 20/20\n",
      "30/30 - 1s - loss: 0.2036 - accuracy: 0.9441\n"
     ]
    }
   ],
   "source": [
    "_= model.fit(\n",
    "    x_train_normalised, \n",
    "    y_train_encoded,\n",
    "    epochs = 20,\n",
    "    batch_size = 2048,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.9395\n",
      "Accuracy of model: 93.94999742507935\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_normalised, y_test_encoded)\n",
    "print(\"Accuracy of model:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import tensorflow as tf \n",
    "import random\n",
    "import  streamlit as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import easygui\n",
    "\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "#creating feature function which we will use to display layers\n",
    "feature_model = tf.keras.models.Model(\n",
    "    model.input,\n",
    "    [layer.output for layer in model.layers]\n",
    ")\n",
    "\n",
    "#loadind dataset again\n",
    "_,(x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#normalising test case\n",
    "x_test = x_test/255\n",
    "\n",
    "#getting a random prediction\n",
    "def get_predictions():\n",
    "    index = np.random.choice(x_test.shape[0])\n",
    "    image = x_test[index, :, :]\n",
    "    image_arr = np.reshape(image, (1, 784))\n",
    "    return feature_model.predict(image_arr), image\n",
    "\n",
    "def get_predictions_user_image(image):\n",
    "    image_arr = np.reshape(image, (1, 784))\n",
    "    return feature_model.predict(image_arr)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()\n",
    "    e97171\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "st.title('Nerual Network Visualizer')\n",
    "st.markdown('<style>h1{color: #e97171;}</style>', unsafe_allow_html=True)\n",
    "st.sidebar.markdown('<h1 style=\"color:#e97171\">Input Image</h1>', unsafe_allow_html=True)\n",
    "\n",
    "def binarize(image):\n",
    "    image = cv2.imread(image)\n",
    "    grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    # Convert RGB to BGR \n",
    "    grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV)\n",
    "    _, contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    preprocessed_digits = []\n",
    "\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "        digit = thresh[y:y+h, x:x+w]\n",
    "\n",
    "        # Resizing that digit to (18, 18)\n",
    "        resized_digit = cv2.resize(digit, (18,18))\n",
    "\n",
    "        # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "        padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
    "\n",
    "        # Adding the preprocessed digit to the list of preprocessed digits\n",
    "        preprocessed_digits.append(padded_digit)\n",
    "    return preprocessed_digits[0]/255.0\n",
    "\n",
    "get_random = True\n",
    "\n",
    "def get_random():\n",
    "    get_random = True\n",
    "    preds, image = get_predictions()\n",
    "    final_preds = [i.tolist() for i in preds]\n",
    "    \n",
    "    pred_dict = {\n",
    "            'prediction':final_preds,\n",
    "            'image': image.tolist()\n",
    "        }\n",
    "    \n",
    "    preds = pred_dict['prediction']\n",
    "    image = pred_dict['image']\n",
    "    image = np.reshape(image, (28,28))\n",
    "    st.sidebar.image(image, width=150)\n",
    "    \n",
    "    for layer, p in enumerate(preds):\n",
    "        \n",
    "        numbers = np.squeeze(np.array(p)) #squeezing to removing the single demension\n",
    "        \n",
    "        #creating layers\n",
    "        plt.figure(figsize=(32,4))\n",
    "        \n",
    "        if layer == 2: # final output layer\n",
    "            row = 1   \n",
    "            col = 10\n",
    "        else:          # dense layer\n",
    "            row = 2\n",
    "            col = 16\n",
    "            \n",
    "        for i, number in enumerate(numbers): \n",
    "            plt.subplot(row,col,i + 1) #subploting every node\n",
    "            plt.imshow(number*np.ones((8, 8, 3)).astype('float32')) #creating 8x8 pixel dimension blocks\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            if layer == 2:\n",
    "                plt.xlabel(str(i), fontsize = 40) #labels for the output layer\n",
    "        plt.subplots_adjust(wspace=0.05, hspace=0.05) #packing the nodes\n",
    "        plt.tight_layout()\n",
    "        st.text('Layer {}'.format(layer + 1))\n",
    "        st.pyplot()\n",
    "    st.markdown('## Final Prediction = {}'.format(np.argmax(preds[2])))\n",
    "\n",
    "def get_random_u(file_upload):\n",
    "    b_image = binarize(file_upload)\n",
    "    st.sidebar.image(b_image, width = 150)\n",
    "    preds = get_predictions_user_image((b_image))\n",
    "    final_preds = [i.tolist() for i in preds]\n",
    "\n",
    "    pred_dict = {\n",
    "            'prediction':final_preds,\n",
    "        }\n",
    "\n",
    "    preds = pred_dict['prediction']\n",
    "\n",
    "    for layer, p in enumerate(preds):\n",
    "\n",
    "        numbers = np.squeeze(np.array(p)) #squeezing to removing the single demension\n",
    "\n",
    "        #creating layers\n",
    "        plt.figure(figsize=(32,4))\n",
    "\n",
    "        if layer == 2: # final output layer\n",
    "            row = 1   \n",
    "            col = 10\n",
    "        else:          # dense layer\n",
    "            row = 2\n",
    "            col = 16\n",
    "\n",
    "        for i, number in enumerate(numbers): \n",
    "            plt.subplot(row,col,i + 1) #subploting every node\n",
    "            plt.imshow(number*np.ones((8, 8, 3)).astype('float32')) #creating 8x8 pixel dimension blocks\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            if layer == 2:\n",
    "                plt.xlabel(str(i), fontsize = 40) #labels for the output layer\n",
    "        plt.subplots_adjust(wspace=0.05, hspace=0.05) #packing the nodes\n",
    "        plt.tight_layout()\n",
    "        st.text('Layer {}'.format(layer + 1))\n",
    "        st.pyplot()\n",
    "    st.markdown('## Final Prediction = {}'.format(np.argmax(preds[2])))\n",
    "\n",
    "def main():\n",
    "    if st.button('Get random predictions'):\n",
    "        get_random()\n",
    "        file_upload = None\n",
    "\n",
    "    elif st.button('Upload'):\n",
    "        file_upload = st.file_uploader()\n",
    "        if file is not None:\n",
    "            if st.button('process'):\n",
    "                get_random_u(file_upload)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Server (Flask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ml_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ml_server.py\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "#loading model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "#creating feature function which we will use to display layers\n",
    "feature_model = tf.keras.models.Model(\n",
    "    model.input,\n",
    "    [layer.output for layer in model.layers]\n",
    ")\n",
    "\n",
    "#loadind dataset again\n",
    "_,(x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#normalising test case\n",
    "x_test = x_test/255\n",
    "\n",
    "#getting a random prediction\n",
    "def get_predictions():\n",
    "    index = np.random.choice(x_test.shape[0])\n",
    "    image = x_test[index, :, :]\n",
    "    image_arr = np.reshape(image, (1, 784))\n",
    "    return feature_model.predict(image_arr), image\n",
    "\n",
    "\n",
    "@app.route('/', methods = ['GET', 'POST']) #defining GET and POST request\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        preds, image = get_predictions()\n",
    "        final_preds = [i.tolist() for i in preds]\n",
    "        return json.dumps({\n",
    "            'prediction':final_preds,\n",
    "            'image': image.tolist()\n",
    "        })\n",
    "    return \"Welcom to the model server!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit Web App 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app1.py\n",
    "\n",
    "import io\n",
    "import  streamlit as st\n",
    "import json\n",
    "import numpy as np\n",
    "import requests \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "\n",
    "URI = 'http://127.0.0.1:5000'\n",
    "\n",
    "st.title('Nerual Network Visualizer')\n",
    "st.sidebar.markdown('## Input Image')\n",
    "\n",
    "if st.button('Get random predictions'):\n",
    "    response = requests.post(URI, data={})\n",
    "    response = json.loads(response.text)\n",
    "    preds = response.get('prediction')\n",
    "    image = response.get('image')\n",
    "    image = np.reshape(image, (28,28))\n",
    "    st.sidebar.image(image, width=150)\n",
    "    \n",
    "    for layer, p in enumerate(preds):\n",
    "        \n",
    "        numbers = np.squeeze(np.array(p)) #squeezing to removing the single demension\n",
    "        \n",
    "        #creating layers\n",
    "        plt.figure(figsize=(32,4))\n",
    "        \n",
    "        if layer == 2: # final output layer\n",
    "            row = 1   \n",
    "            col = 10\n",
    "        else:          # dense layer\n",
    "            row = 2\n",
    "            col = 16\n",
    "            \n",
    "        for i, number in enumerate(numbers): \n",
    "            plt.subplot(row,col,i + 1) #subploting every node\n",
    "            plt.imshow(number*np.ones((8, 8, 3)).astype('float32')) #creating 8x8 pixel dimension blocks\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            if layer == 2:\n",
    "                plt.xlabel(str(i), fontsize = 40) #labels for the output layer\n",
    "        plt.subplots_adjust(wspace=0.05, hspace=0.05) #packing the nodes\n",
    "        plt.tight_layout()\n",
    "        st.text('Layer {}'.format(layer + 1))\n",
    "        st.pyplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile requirement.py\n",
    "import tensorflow \n",
    "import random\n",
    "import  streamlit \n",
    "import numpy \n",
    "import requests \n",
    "import matplotlib\n",
    "import cv2\n",
    "import PIL\n",
    "import easygui\n",
    "\n",
    "lib_list = [tensorflow, streamlit, numpy, matplotlib, cv2, PIL]\n",
    "lib_list2 = ['tensorflow', 'streamlit', 'numpy', 'matplotlib', 'cv2', 'PIL']\n",
    "\n",
    "dependencies = []\n",
    "for i in range(len(lib_list)):\n",
    "    with open('requirements.txt', 'a+') as file:\n",
    "        file.write('{}={}\\n'.format(lib_list2[i],lib_list[i].__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Procfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Procfile\n",
    "web: sh setup.sh && streamlit run rps_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "mkdir -p ~/.streamlit/ echo \"\\\n",
    "[server]\\n\\\n",
    "port = $PORT\\n\\\n",
    "enableCORS = false\\n\\\n",
    "headless = true\\n\\\n",
    "\\n\\\n",
    "\" > ~/.streamlit/config.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
